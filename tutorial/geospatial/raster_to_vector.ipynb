{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cartopy tutorial: Transforming raster to vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going from raster data to vector is a surprisingly common task, even though we may not always think of it in those terms.\n",
    "\n",
    "\n",
    "### Contouring\n",
    "\n",
    "Perhaps the most obvious raster to vector transformation is contouring.\n",
    "A contouring algorithm takes an array of numbers, and computes routes of iso-lines or iso-surfaces.\n",
    "\n",
    "Let's start with matplotlib's contouring routines. The isosurface implementation is available through ``plt.contourf`` (filled contours), while the isoline implementation is ``plt.contour`` (line contours):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "from cartopy.examples.waves import sample_data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "lons, lats, data = sample_data()\n",
    "\n",
    "plt.figure()\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "cs = plt.contourf(\n",
    "    lons, lats, data, 5,  # Choose approximately 5 sensible levels.\n",
    "    transform=ccrs.PlateCarree())\n",
    "ax.coastlines()\n",
    "plt.colorbar(orientation='horizontal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pick out one of these contours. We could choose to pick out a line (``contour``) or a polygon (``contourf``).\n",
    "Since we have already produced filled contours, let's use those:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cs.levels)\n",
    "print('N levels: {}'.format(len(cs.levels)))\n",
    "print('N collections: {}'.format(len(cs.collections)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cs.levels[4:6])\n",
    "print(cs.collections[4])\n",
    "paths = cs.collections[4].get_paths()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to convert these matplotlib Paths into Shapely geometries. The [``descartes``](https://pypi.org/project/descartes/) package is designed to do precisely this, but cartopy also has such functionality that has been tuned for performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cartopy.mpl.patch import path_to_geos\n",
    "import shapely.ops\n",
    "\n",
    "# Produces a list of shapely geometries.\n",
    "geoms = []\n",
    "for path in paths:\n",
    "    geoms.extend(path_to_geos(path))\n",
    "\n",
    "# Flatten the whole thing down to a single MultiPolygon\n",
    "polygon = shapely.ops.unary_union(geoms)\n",
    "polygon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could use this geometry for any number of vector-type operations, but for now, let's just save it to disk. GeoJSON is a good choice for this kind of geometry - GeoJSON has become ubiquitous on the internet for its simpliciy and its interoperability with a number of popular tools/frameworks (including GitHub)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import shapely.geometry as sgeom\n",
    "\n",
    "with open('contour.geojson', 'w') as fh:\n",
    "    json.dump(sgeom.mapping(polygon), fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've uploaded this geojson to a GitHub gist to show how GitHub renders this file: https://gist.github.com/pelson/837ca8c01d38157a2d634dcf97260e45"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be aware that the GeoJSON specification states that geometries MUST be saved in WGS84. The default PlateCarree instance is in fact equivalent to WGS84, so in this case we didn't need to convert the geometry. If had needed to convert it we could project the geometry with ``ccrs.PlateCarree().project_geometry(geometry, source_crs)``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data space vs pixel space\n",
    "\n",
    "So far we have used ``matplotlib.contour[f]`` to produce our contours, which conveniently returns contours in *data* coordinates. Sometimes we want to use tools that don't work in coordinate space, and which simply return pixel locations.\n",
    "\n",
    "One of the most basic examples of this is numpy's ``where`` function. Let's use that to identify the yellow sections from the Wikipedia image below:\n",
    "\n",
    "![Wikipedia route around the world](../../resources/640px-Around_the_World_in_Eighty_Days_map.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import skimage.io\n",
    "\n",
    "# Image has shape: (y: 296, x: 640, RGBA: 4)\n",
    "atw80d = skimage.io.imread(\n",
    "    '../../resources/640px-Around_the_World_in_Eighty_Days_map.png')\n",
    "\n",
    "yellowish = ((atw80d[:, :, 0] > 200) &  # Lots of Red.\n",
    "             (atw80d[:, :, 1] > 200) &  # Lots of Green.\n",
    "             (atw80d[:, :, 2] < 100) &  # Not lots of Blue.\n",
    "             (atw80d[:, :, 3] > 250))   # Not transparent.\n",
    "\n",
    "ind_y, ind_x = np.where(yellowish)\n",
    "print('Number of yellow-ish pixels: ', len(ind_x))\n",
    "print('x indexes: ', ind_x)\n",
    "print('y indexes: ', ind_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversion between pixel locations and data locations is currently quite manual, but the following function will allow us to go from pixel centers to data coordinates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixels_to_data(extent, shape, i, j):\n",
    "    \"\"\"Converts from coordinates of the array to data coordinates.\"\"\"\n",
    "    xmin, xmax, ymin, ymax = extent\n",
    "    x_range = xmax - xmin\n",
    "    y_range = ymax - ymin\n",
    "    \n",
    "    pix_width = x_range / shape[1]\n",
    "    pix_height = y_range / shape[0]\n",
    "\n",
    "    # For y handle the fact that the image's pixels\n",
    "    # start at the top (in mpl that is what origin='upper' means).\n",
    "    j = shape[0] - j\n",
    "\n",
    "    return (xmin + pix_width * (i + 0.5),\n",
    "            ymin + pix_height * (j + 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we feed in the image extent and the x and y indices computed using ``np.where``, we get the pixel location in the coordinate system of the image (Robinson):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the extents computed in an earlier exercise.\n",
    "extent = [-13636707, 17044670, -6308712, 8565930]\n",
    "\n",
    "# Note: Data coords in Robinson.\n",
    "xs, ys = pixels_to_data(\n",
    "    extent, atw80d.shape,\n",
    "    ind_x, ind_y)\n",
    "\n",
    "print('Last 3 x coordinates (Robinson): ', xs[-3:])\n",
    "print('Last 3 y coordinates (Robinson): ', ys[-3:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the coordinates, let's plot the pixels we have identified:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "plt.figure()\n",
    "\n",
    "rob = ccrs.Robinson(central_longitude=11.25)\n",
    "ax = plt.axes(projection=rob)\n",
    "\n",
    "ax.gridlines(color='gray', linestyle='--')\n",
    "ax.coastlines()\n",
    "ax.imshow(atw80d, extent=extent,\n",
    "          transform=rob, origin='upper')\n",
    "ax.set_global()\n",
    "\n",
    "plt.plot(xs, ys, transform=rob,\n",
    "         linestyle='none', marker='o',\n",
    "         markeredgecolor='k', color='yellow')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take this a step further and use [scikit-image](http://scikit-image.org/) to pull out the track. Let's welcome **Juan Nunez-Iglesias (@jni)** for a guest appearance to talk us through it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.cluster.vq import vq as vector_quantization\n",
    "import skimage.io\n",
    "\n",
    "\n",
    "# Load the full image (not the 640px one), and scale the pixels\n",
    "# between 0-1.\n",
    "atw80d = skimage.io.imread(\n",
    "    '../../resources/Around_the_World_in_Eighty_Days_map.png') / 255\n",
    "\n",
    "colors = np.array(\n",
    "[[1. , 1. , 1. ],  # white\n",
    " [0.7, 0.7, 0.7],  # gray\n",
    " [0. , 0. , 0. ],  # black\n",
    " [1. , 1. , 0. ],  # yellow\n",
    " [0. , 0. , 1. ]]  # blue\n",
    ")\n",
    "atw_nearest_color_idx, error = vector_quantization(\n",
    "    atw80d.reshape((-1, 3)), colors)\n",
    "atw_quantized = colors[atw_nearest_color_idx].reshape(atw80d.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To confirm the quantization, let's take a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax0, ax1) = plt.subplots(2, 1, sharex=True, sharey=True)\n",
    "ax0.imshow(atw80d)\n",
    "ax1.imshow(atw_quantized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.morphology import remove_small_objects\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "# Find all the colors that don't have a zero (gray and white).\n",
    "track_et_al = np.sum(atw_quantized == 0, axis=2) > 0\n",
    "\n",
    "# Now use skimage to label the data, and only keep the longest\n",
    "# track.\n",
    "pixel_groups, n_groups = ndi.label(track_et_al)\n",
    "group_sizes = np.bincount(pixel_groups.ravel())\n",
    "track_size = np.max(group_sizes[1:])\n",
    "track_fat = remove_small_objects(\n",
    "    track_et_al, min_size=track_size - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, skeletonize the image to remove the line width from the image, and finally compute the coordinates of the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.morphology import skeletonize\n",
    "from itertools import product\n",
    "\n",
    "track = skeletonize(track_fat)\n",
    "point_coordinates = np.array(np.nonzero(track)).T\n",
    "leftmost_idx = np.argmin(point_coordinates[:, 1])\n",
    "start = point_coordinates[leftmost_idx]\n",
    "\n",
    "# Function to walk the skeleton and extract the pixel\n",
    "# coordinates of the route. If you are doing this for real, you\n",
    "# might like to check out https://jni.github.io/skan/\n",
    "def points_to_path(point_coordinates, start_point, track_image):\n",
    "    neighbor_idxs = list(product((-1, 0, 1), (-1, 0, 1)))\n",
    "    neighbor_idxs.remove((0, 0))\n",
    "\n",
    "    not_visited = track_image.copy()\n",
    "    \n",
    "    path = np.zeros_like(point_coordinates)\n",
    "    path[0] = start\n",
    "    npoints = point_coordinates.shape[0]\n",
    "    currpoint = start\n",
    "\n",
    "    for i in range(1, npoints):\n",
    "        not_visited[tuple(currpoint)] = False\n",
    "        for neighbor in currpoint + neighbor_idxs:\n",
    "            if not_visited[tuple(neighbor)]:\n",
    "                path[i] = neighbor\n",
    "                currpoint = neighbor\n",
    "                break\n",
    "    return path\n",
    "\n",
    "path_coords = points_to_path(point_coordinates, start, track)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To confirm this has done what we wanted, let's look at the path on a map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.coastlines()\n",
    "xs, ys = pixels_to_data(\n",
    "    extent, atw80d.shape,\n",
    "    path_coords[:, 1], path_coords[:, 0])\n",
    "\n",
    "# Remember, the coordinate points are projected Robinson.\n",
    "rob = ccrs.Robinson(central_longitude=11.25)\n",
    "ax.plot(xs, ys, transform=rob)\n",
    "\n",
    "ax.set_global()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from the gap, this looks good. The gap is a genuine artifact of the original image, but is still not desirable. Let's project the geometry we have to Plate Carree and then we'll close the loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shapely.geometry as sgeom\n",
    "\n",
    "track_geom = sgeom.LineString(np.stack([xs, ys], axis=-1))\n",
    "\n",
    "pc_track_geom = ccrs.PlateCarree().project_geometry(track_geom, rob)\n",
    "pc_track_geom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, we can compute the endpoints nearest to each other, and construct a line between them. We can then use shapely's linemerge to join all three lines together: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shapely.ops\n",
    "missing_segment = sgeom.LineString(\n",
    "    shapely.ops.nearest_points(*pc_track_geom.geoms))\n",
    "\n",
    "route = shapely.ops.linemerge(\n",
    "    list(pc_track_geom.geoms) + [missing_segment])\n",
    "route"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5.1:** Now that we have projected the route to Plate Carree coordinates, draw the line (using the ``add_geometries`` method) on top of a Robinson map with coastlines.\n",
    "\n",
    "\n",
    "*Extension:* Save the route geometry as a GeoJSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE 5.1:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary style=\"margin-top: 1em; margin-left: 1em;\"><b>Click to show solution for 5.1</b></summary>\n",
    "<pre>\n",
    "plt.figure()\n",
    "\n",
    "ax = plt.axes(projection=rob)\n",
    "ax.coastlines()\n",
    "ax.add_geometries(\n",
    "    [route], ccrs.PlateCarree(),\n",
    "    edgecolor='blue', facecolor='none', linewidth=2)\n",
    "ax.set_global()\n",
    "plt.show()\n",
    "</pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE 5.1 EXTENSION:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary style=\"margin-top: 1em; margin-left: 1em;\"><b>Click to show solution for 5.1 extension</b></summary>\n",
    "<pre>\n",
    "import json\n",
    "import shapely.geometry as sgeom\n",
    "\n",
    "with open('route.geojson', 'w') as fh:\n",
    "    json.dump(sgeom.mapping(route), fh)\n",
    "</pre>\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
